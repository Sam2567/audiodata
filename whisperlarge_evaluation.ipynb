{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36d9480d8f744b4bbf035ccdd9f1ccab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/87 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b097fbd850a458c93c559e89e22c57f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0/87 [00:00<?, ?files/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d17ec2c337804cfea6f1817974ba31db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e00fe562ec84a4ea3ca4070806b54e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/87 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab8dd67419ea4f11acfa6e4145c359ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c8da1fb09ce4db5901e1db9be8f34bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0/79 [00:00<?, ?files/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57f3ad60fd0948ddbab274c5eb015143",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "291326cc4df34053a2ba013e54dc6cf5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/79 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "889bd0921a5f4c7a8caadf2518dd0187",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/124 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2be9805150f44d11ac76dd3c156c7e48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/42 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\qscre\\miniconda3\\envs\\aml\\Lib\\site-packages\\transformers\\training_args.py:1545: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from datasets import concatenate_datasets, load_dataset, Audio, DatasetDict\n",
    "from transformers import AutoFeatureExtractor, AutoModelForAudioClassification, TrainingArguments, Trainer, EarlyStoppingCallback\n",
    "import numpy as np\n",
    "import torch\n",
    "import evaluate\n",
    "from random import randint\n",
    "\n",
    "# Define the device\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch_dtype = torch.float16 if torch.cuda.is_available() else torch.float32\n",
    "\n",
    "# Load the feature extractor and the saved model from \"models/whisper-large-v3_ADReSSo\"\n",
    "model_name = \"distil-whisper/distil-large-v3\" # Model name\n",
    "feature_extractor = AutoFeatureExtractor.from_pretrained(model_name)\n",
    "\n",
    "# Load the model from the saved directory\n",
    "model = AutoModelForAudioClassification.from_pretrained(\n",
    "    \"models/whisper-large-v3_ADReSSo/checkpoint-93\", num_labels=2, ignore_mismatched_sizes=True\n",
    ")\n",
    "model.to(device)\n",
    "\n",
    "# Preprocessing function for the audio data\n",
    "preprocess = lambda examples: feature_extractor(\n",
    "    [i[\"array\"][(n := randint(0, len(i[\"array\"]) - (m := min(len(i[\"array\"]), feature_extractor.sampling_rate * 30)))) : n + m] for i in examples[\"audio\"]],\n",
    "    sampling_rate=feature_extractor.sampling_rate,\n",
    "    do_normalize=True,\n",
    ")\n",
    "\n",
    "#### LOAD DATASET HERE ############\n",
    "AD_PATH = 'ADReSSo21/diagnosis/train/audio/ad'\n",
    "CN_PATH = 'ADReSSo21/diagnosis/train/audio/cn'\n",
    "\n",
    "ad_dataset = (\n",
    "    load_dataset(AD_PATH)\n",
    "    .cast_column(\"audio\", Audio(sampling_rate=feature_extractor.sampling_rate))\n",
    ")\n",
    "ad_dataset = ad_dataset.map(lambda example: {\"label\": 0})\n",
    "\n",
    "cn_dataset = (\n",
    "    load_dataset(CN_PATH)\n",
    "    .cast_column(\"audio\", Audio(sampling_rate=feature_extractor.sampling_rate))\n",
    ")\n",
    "cn_dataset = cn_dataset.map(lambda example: {\"label\": 1})\n",
    "\n",
    "dataset = concatenate_datasets([ad_dataset[\"train\"], cn_dataset[\"train\"]])\n",
    "dataset = DatasetDict({\"train\": dataset})\n",
    "dataset[\"train\"], dataset[\"valid\"] = dataset[\"train\"].train_test_split(0.25).values()\n",
    "dataset = dataset.map(preprocess, remove_columns=\"audio\", batched=True)\n",
    "\n",
    "train_dataset = dataset[\"train\"].with_format(\"torch\")\n",
    "val_dataset = dataset[\"valid\"].with_format(\"torch\")\n",
    "\n",
    "# Load evaluation metrics\n",
    "accuracy = evaluate.load(\"accuracy\")\n",
    "f1 = evaluate.load(\"f1\")\n",
    "specificity = evaluate.load(\"nevikw39/specificity\")\n",
    "\n",
    "# Define training arguments (for evaluation purposes)\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"models/whisper-large-v3_ADReSSo\" + (\"_fp16\" if False else \"\"),\n",
    "    fp16=False,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    save_total_limit=1,\n",
    "    per_device_train_batch_size=2,\n",
    "    per_device_eval_batch_size=2,\n",
    "    gradient_accumulation_steps=4,\n",
    "    num_train_epochs=10,\n",
    "    warmup_ratio=0.1,\n",
    "    logging_steps=10,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    push_to_hub=False,\n",
    ")\n",
    "\n",
    "# Trainer setup\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    tokenizer=feature_extractor,\n",
    "    compute_metrics=lambda eval_pred: (\n",
    "        accuracy.compute(\n",
    "            predictions=(pred := np.argmax(eval_pred.predictions, axis=1)),\n",
    "            references=eval_pred.label_ids,\n",
    "        ) | f1.compute(\n",
    "            predictions=pred,\n",
    "            references=eval_pred.label_ids,\n",
    "        ) | specificity.compute(\n",
    "            predictions=pred,\n",
    "            references=eval_pred.label_ids,\n",
    "        )\n",
    "    ),\n",
    "    callbacks=[EarlyStoppingCallback(10)],\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\qscre\\miniconda3\\envs\\aml\\Lib\\site-packages\\transformers\\models\\whisper\\modeling_whisper.py:599: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:555.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79f46f1ff05d4b949e9f9ae58f9adc71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/21 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation results: {'eval_loss': 0.4877254366874695, 'eval_model_preparation_time': 0.0033, 'eval_accuracy': 0.9047619047619048, 'eval_f1': 0.92, 'eval_specificity': 0.8823529411764706, 'eval_runtime': 6.2097, 'eval_samples_per_second': 6.764, 'eval_steps_per_second': 3.382}\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the validation dataset\n",
    "eval_result = trainer.evaluate()\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(\"Evaluation results:\", eval_result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
